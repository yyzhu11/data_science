{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From this notebook, we are going to build classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sales.csv')\n",
    "df.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df.purchase_date).dt.year\n",
    "train_raw = df[df.year < 2015]\n",
    "test_raw = df[df.year >= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_level</th>\n",
       "      <th>maker</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$333k</td>\n",
       "      <td>$300,492</td>\n",
       "      <td>3 Ton 90 Kg</td>\n",
       "      <td>Dec 19 2008</td>\n",
       "      <td>Q,B</td>\n",
       "      <td>advanced</td>\n",
       "      <td>M14122</td>\n",
       "      <td>IN732052,IN732053</td>\n",
       "      <td>2.76 meters</td>\n",
       "      <td>97 cm</td>\n",
       "      <td>26 cm</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cost     price       weight purchase_date product_type product_level  \\\n",
       "0  $333k  $300,492  3 Ton 90 Kg   Dec 19 2008          Q,B      advanced   \n",
       "\n",
       "    maker         ingredient       height  width  depth  year  \n",
       "0  M14122  IN732052,IN732053  2.76 meters  97 cm  26 cm  2008  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> We define a categorical target **luxury**. If **price** is higher than 500k dollars, we say this item is a **luxury**, and use integer 1 to mark it as positive. Otherwise, we use 0 to mark it as negative. Get the target Series for training and testing data sets (**y_train** and **y_test**), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw['price'] = train_raw['price'].map(lambda x: x if type(x) is float else float(x.strip('$').replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_raw['price'] = test_raw['price'].map(lambda x: x if type(x) is float else float(x.strip('$').replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw['luxury'] = ''\n",
    "# test_raw['luxury'] = ''\n",
    "# train_raw['luxury'].values[:] = 0\n",
    "# test_raw['luxury'].values[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw['luxury'][train_raw[train_raw.price > 500000].index] = 1\n",
    "# test_raw['luxury'][test_raw[test_raw.price > 500000].index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw[\"luxury\"] = train_raw[\"price\"].map(lambda x: 1 if float(x.strip(\"$\").replace(\",\", \"\")) > 500000 else 0)\n",
    "test_raw[\"luxury\"] = test_raw[\"price\"].map(lambda x: 1 if float(x.strip(\"$\").replace(\",\", \"\")) > 500000 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_raw.luxury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_raw.luxury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Visualize the comparison between the numbers of positive and negative data points. **Hint:** You could use either bar chart or pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test set')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAFNCAYAAACwk0NsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg+klEQVR4nO3dfbRddX3n8fdHnrQFDcg1RRIbqqkttquRuQLWzoxKlYe2A85YBqej0UUbnUJHBscR7JqBPjALZ1TU1tKJJQJTKzI+LFJLVUSsY5cgwVLkQUqqYZFMIJEnoShtwnf+OL8rx3jvzb3hnnP2uXm/1jrr7P3bv73P95C7fnz209mpKiRJktQ9Txt1AZIkSZqeQU2SJKmjDGqSJEkdZVCTJEnqKIOaJElSRxnUJEmSOsqgprGU5C+TrB51HZIkDZJBTUOT5NG+1xNJvts3/2vz2VZVnVhVlw2q1l0lWZGkkuw7rM+U1E0LOZa17X0xya8PoM43JvnyQm9Xw+X/dDQ0VXXg1HSSTcCvV9Xnd+2XZN+q2jHM2iRpruY6lkkLwSNqGrkkL0+yOck7ktwLfDjJwUk+nWR7kgfb9LK+db6/Bzq115jk3a3vt5KcOMvnvSPJliSPJLkzyXGt/WlJzkny90nuT3JlkkPaal9q7w+1veaXDug/h6QxNdsYkuTpSf60tT+U5MYkS5NcAPxz4A/b2PKH02x32nXbsmcluSTJ1jau/X6SfZL8NPDHwEvbdh8a4n8KLSCDmrrix4BDgB8H1tD72/xwm38e8F3ghwawPscAdwKHAv8DuCRJdu2U5IXAmcBLquog4HhgU1v8W8ApwL8Engs8CHywLfsX7X1JVR1YVV/Zky8paVGbbQxZDTwLWA48G3gL8N2q+m3g/wJntrHlzGm2O+26bdmlwA7gBcCLgVfTO8J3R+v3lbbdJQv5RTU8BjV1xRPAeVX1eFV9t6rur6pPVNVjVfUIcAG9wW8md1fVh6pqJ3AZcBiwdJp+O4EDgCOT7FdVm6rq79uytwC/XVWbq+px4HzgtV6XJmmOZhtD/oleyHpBVe2sqpuq6jtz3O6067ajaicBZ1XVP1TVNuAi4LSF/mIaHf8HpK7YXlXfm5pJ8iP0BpwTgINb80FJ9mlhbFf3Tk1U1WPtYNqBu3aqqo1JzqI3gL4oyWeBs6vq/9E7evepJE/0rbKT6QOfJO1qtjHkf9M7InZFkiXAn9ILdf80h+1Ou277vP2ArX0nEJ4G3POUv4k6wyNq6oraZf5twAuBY6rqmTx56vGHTmfO+4Oq/qyqfoHeIFfAu9qie4ATq2pJ3+vpVbVlmvokaVczjiFV9U9V9TtVdSTw88AvA29o6806vsyy7j3A48ChfZ/3zKp60Vy2q/FgUFNXHUTvGoyH2sW45y3ERpO8MMkrkxwAfK99xtTe7x8DFyT58dZ3IsnJbdn21u8nFqIOSYvSjGNIklck+dkk+wDfoXc6c2rsuY9ZxpaZ1q2qrcDngPckeWa7meH5SaYuE7kPWJZk/wF8Vw2JQU1d9T7gGcC3geuBzyzQdg8ALmzbvRd4DnBuW/Z+YD3wuSSPtM89BnqnU+ldJ/fX7a6rYxeoHkmLx4xjCL0bpj5OL2jdAfwVvVOaU+u9tt21/oFptjvbum8A9gdup3fzwsfpXaML8AXgNuDeJN9eoO+oIUuVR0YlSZK6yCNqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRpD7TH9PxNkk+3+SOS3JBkY5KPTd1pl+SANr+xLV8x0sIljRWDmiTtmbfSuwNvyruAi6rqBfTuvju9tZ8OPNjaL+LJ3+2TpN1alHd9HnroobVixYpRlyFpiG666aZvV9XEMD4ryTJ6jyq7ADgb+BV6v7X3Y1W1I8lLgfOr6vj29Ivzq+or7VFC9wITNcvg6xgm7V1mG78W5SOkVqxYwYYNG0ZdhqQhSnL3ED/ufcB/offDzNB7DuNDVbWjzW8GDm/Th9Me6dNC3MOt/w/8rlWSNcAagOc973mOYdJeZLbxy1OfkjQPSX4Z2FZVNy3kdqtqbVVNVtXkxMRQDgxKGgOL8oiaJA3Qy4B/leQk4OnAM+n9svySJPu2o2rLgC2t/xZ6D9Te3E59Pgu4f/hlSxpHHlGTpHmoqnOrallVrQBOA75QVb8GXAe8tnVbDVzVpte3edryL8x2fZok9TOoSdLCeAdwdpKN9K5Bu6S1XwI8u7WfDZwzovokjSFPfUrSHqqqLwJfbNPfBI6eps/3gF8damGSFg2PqEmSJHWUQU2SJKmjDGqSJEkdZVCTJEnqKIOaJElSRxnUJEmSOsqf5wBWnPMXoy5B09h04S+NugSp8xy/ussxTAvBI2qSJEkdZVCTJEnqqIEFtSTLk1yX5PYktyV5a2s/P8mWJDe310l965ybZGOSO5Mc39d+QmvbmMTHr0iSpL3CIK9R2wG8raq+luQg4KYk17RlF1XVu/s7JzmS3gOOXwQ8F/h8kp9siz8IvArYDNyYZH1V3T7A2iVJkkZuYEGtqrYCW9v0I0nuAA6fZZWTgSuq6nHgW+0BxlPPzdvYnqNHkitaX4OaJEla1IZyjVqSFcCLgRta05lJbkmyLsnBre1w4J6+1Ta3tpnaJUmSFrWBB7UkBwKfAM6qqu8AFwPPB1bRO+L2ngX6nDVJNiTZsH379oXYpCRJ0kgNNKgl2Y9eSPtIVX0SoKruq6qdVfUE8CGePL25BVjet/qy1jZT+w+oqrVVNVlVkxMTEwv/ZSRJkoZskHd9BrgEuKOq3tvXflhft9cAt7bp9cBpSQ5IcgSwEvgqcCOwMskRSfand8PB+kHVLUmS1BWDvOvzZcDrga8nubm1vRN4XZJVQAGbgDcDVNVtSa6kd5PADuCMqtoJkORM4LPAPsC6qrptgHVLkiR1wiDv+vwykGkWXT3LOhcAF0zTfvVs60mSJC1GPplAkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJmockT0/y1SR/m+S2JL/T2i9N8q0kN7fXqtaeJB9IsrE94/iokX4BSWNlkD94K0mL0ePAK6vq0faYvC8n+cu27O1V9fFd+p9I70krK4Fj6D3v+JihVStprHlETZLmoXoebbP7tVfNssrJwOVtveuBJbs8Sk+SZmRQk6R5SrJPezTeNuCaqrqhLbqgnd68KMkBre1w4J6+1Te3NknaLYOaJM1TVe2sqlXAMuDoJD8DnAv8FPAS4BDgHfPZZpI1STYk2bB9+/aFLlnSmDKoSdIeqqqHgOuAE6pqazu9+TjwYeDo1m0LsLxvtWWtbddtra2qyaqanJiYGHDlksaFQU2S5iHJRJIlbfoZwKuAb0xdd5YkwCnArW2V9cAb2t2fxwIPV9XWoRcuaSx516ckzc9hwGVJ9qG3s3tlVX06yReSTAABbgbe0vpfDZwEbAQeA940/JIljSuDmiTNQ1XdArx4mvZXztC/gDMGXZekxclTn5IkSR1lUJMkSeoog5okSVJHGdQkSZI6yqAmSZLUUQY1SZKkjjKoSZIkdZRBTZIkqaMMapIkSR1lUJMkSeoog5okSVJHGdQkSZI6yqAmSZLUUQY1SZKkjjKoSZIkdZRBTZIkqaMMapIkSR1lUJMkSeoog5okSVJHGdQkSZI6yqAmSZLUUQY1SZKkjjKoSZIkdZRBTZIkqaMMapIkSR1lUJOkeUjy9CRfTfK3SW5L8jut/YgkNyTZmORjSfZv7Qe0+Y1t+YqRfgFJY8WgJknz8zjwyqr6OWAVcEKSY4F3ARdV1QuAB4HTW//TgQdb+0WtnyTNycCCWpLlSa5Lcnvb63xraz8kyTVJ7mrvB7f2JPlA2+u8JclRfdta3frflWT1oGqWpN2pnkfb7H7tVcArgY+39suAU9r0yW2etvy4JBlOtZLG3SCPqO0A3lZVRwLHAmckORI4B7i2qlYC17Z5gBOBle21BrgYesEOOA84BjgaOG8q3EnSKCTZJ8nNwDbgGuDvgYeqakfrshk4vE0fDtwD0JY/DDx7qAVLGlsDC2pVtbWqvtamHwHuoDdg9e9d7rrXeXnbW70eWJLkMOB44JqqeqCqHqQ3KJ4wqLolaXeqamdVrQKW0duB/Kmnus0ka5JsSLJh+/btT3VzkhaJoVyj1i6efTFwA7C0qra2RfcCS9v09/c6m6k90pnaJWmkquoh4DrgpfR2Lvdti5YBW9r0FmA5QFv+LOD+aba1tqomq2pyYmJi0KVLGhMDD2pJDgQ+AZxVVd/pX1ZVRe/ajoX4HPdGJQ1ckokkS9r0M4BX0TtjcB3w2tZtNXBVm17f5mnLv9DGPknarYEGtST70QtpH6mqT7bm+9opTdr7ttb+/b3OZmqPdKb2H+DeqKQhOQy4LsktwI30Ls34NPAO4OwkG+ldg3ZJ638J8OzWfjZPXpcrSbu17+677Jl2V9MlwB1V9d6+RVN7lxfyw3udZya5gt6NAw9X1dYknwX+e98NBK8Gzh1U3ZI0m6q6hd6lHLu2f5Pe9Wq7tn8P+NUhlCZpERpYUANeBrwe+Hq7OwrgnfQC2pVJTgfuBk5ty64GTgI2Ao8BbwKoqgeS/B69PVeA362qBwZYtyRJUicMLKhV1ZeBmX4r6Lhp+hdwxgzbWgesW7jqJEmSus8nE0iSJHWUQU2SJKmjDGqSJEkdZVCTJEnqKIOaJElSRxnUJEmSOsqgJkmS1FEGNUmSpI4yqEmSJHWUQU2SJKmjDGqSJEkdZVCTJEnqKIOaJElSRxnUJEmSOsqgJkmS1FEGNUmSpI4yqEmSJHWUQU2SJKmjDGqSJEkdZVCTJEnqKIOaJElSRxnUJEmSOsqgJkmS1FEGNUmahyTLk1yX5PYktyV5a2s/P8mWJDe310l965ybZGOSO5McP7rqJY2bfUddgCSNmR3A26rqa0kOAm5Kck1bdlFVvbu/c5IjgdOAFwHPBT6f5CeraudQq5Y0ljyiJknzUFVbq+prbfoR4A7g8FlWORm4oqoer6pvARuBowdfqaTFwKAmSXsoyQrgxcANrenMJLckWZfk4NZ2OHBP32qbmT3YSdL3GdQkaQ8kORD4BHBWVX0HuBh4PrAK2Aq8Z57bW5NkQ5IN27dvX+hyJY0pg5okzVOS/eiFtI9U1ScBquq+qtpZVU8AH+LJ05tbgOV9qy9rbT+gqtZW1WRVTU5MTAz2C0gaGwY1SZqHJAEuAe6oqvf2tR/W1+01wK1tej1wWpIDkhwBrAS+Oqx6JY037/qUpPl5GfB64OtJbm5t7wRel2QVUMAm4M0AVXVbkiuB2+ndMXqGd3xKmiuDmiTNQ1V9Gcg0i66eZZ0LgAsGVpSkRctTn5IkSR1lUJMkSeoog5okSVJHGdQkSZI6yqAmSZLUUQY1SZKkjjKoSZIkdZRBTZIkqaMMapIkSR01sKCWZF2SbUlu7Ws7P8mWJDe310l9y85NsjHJnUmO72s/obVtTHLOoOqVJEnqmkEeUbsUOGGa9ouqalV7XQ2Q5EjgNOBFbZ0/SrJPkn2ADwInAkfSe5bekQOsWZIkqTMG9qzPqvpSkhVz7H4ycEVVPQ58K8lG4Oi2bGNVfRMgyRWt7+0LXa8kSVLXjOIatTOT3NJOjR7c2g4H7unrs7m1zdQuSZK06A07qF0MPB9YBWwF3rNQG06yJsmGJBu2b9++UJuVJEkamaEGtaq6r6p2VtUTwId48vTmFmB5X9dlrW2m9um2vbaqJqtqcmJiYuGLlyRJGrI5BbUkL5tL2xy2c1jf7GuAqTtC1wOnJTkgyRHASuCrwI3AyiRHJNmf3g0H6+f7uZK0q4Ua1yRpkOZ6M8EfAEfNoe37knwUeDlwaJLNwHnAy5OsAgrYBLwZoKpuS3IlvZsEdgBnVNXOtp0zgc8C+wDrquq2OdYsSbOZ97gmScM2a1BL8lLg54GJJGf3LXomveA0o6p63TTNl8zS/wLggmnarwaunu2zJGmunsq4JknDtrsjavsDB7Z+B/W1fwd47aCKkqQBclyTNDZmDWpV9VfAXyW5tKruHlJNkjQwjmuSxslcr1E7IMlaYEX/OlX1ykEUJUlD4LgmqfPmGtT+D/DHwJ8AOwdXjiQNjeOapM6ba1DbUVUXD7QSSRouxzVJnTfXH7z98yS/meSwJIdMvQZamSQNluOapM6b6xG11e397X1tBfzEwpYjSUPjuCap8+YU1KrqiEEXIknDtKfjWpLlwOXAUnrBbm1Vvb8djfsYvZsTNgGnVtWDSQK8HzgJeAx4Y1V97al/A0l7gzkFtSRvmK69qi5f2HIkaTiewri2A3hbVX0tyUHATUmuAd4IXFtVFyY5BzgHeAdwIr3H4q0EjgEubu+StFtzPfX5kr7ppwPHAV+jt1cpSeNoj8a1qtoKbG3TjyS5AzgcOJneY/MALgO+SC+onQxcXlUFXJ9kSZLD2nYkaVZzPfX5W/3zSZYAVwyiIEkahoUY15KsAF4M3AAs7Qtf99I7NQq9EHdP32qbW5tBTdJuzfWuz139A+B1a5IWk3mNa0kOBD4BnFVV3+lf1o6e1Xw+PMmaJBuSbNi+fft8VpW0iM31GrU/58lBZx/gp4ErB1WUJA3aUxnXkuxHL6R9pKo+2ZrvmzqlmeQwYFtr3wIs71t9WWv7AVW1FlgLMDk5Oa+QJ2nxmus1au/um94B3F1VmwdQjyQNyx6Na+0uzkuAO6rqvX2L1tP7yY8L2/tVfe1nJrmC3k0ED3t9mqS5mtOpz/YQ428ABwEHA/84yKIkadCewrj2MuD1wCuT3NxeJ9ELaK9Kchfwi20e4Grgm8BG4EPAby7ct5C02M311OepwP+kdxdTgD9I8vaq+vgAa5OkgdnTca2qvtz6T+e4afoXcMZTq1bS3mqupz5/G3hJVW0DSDIBfB4wqEkaV45rkjpvrnd9Pm1qMGvun8e6ktRFjmuSOm+uR9Q+k+SzwEfb/L+ld92FJI0rxzVJnTdrUEvyAno/4vj2JP8a+IW26CvARwZdnCQtNMc1SeNkd0fU3gecC9B+K+iTAEl+ti37lQHWJkmD8D4c1ySNid1dj7G0qr6+a2NrWzGQiiRpsBzXJI2N3QW1JbMse8YC1iFJw7JklmWOa5I6ZXdBbUOS39i1McmvAzcNpiRJGijHNUljY3fXqJ0FfCrJr/HkADYJ7A+8ZoB1SdKgnIXjmqQxMWtQq6r7gJ9P8grgZ1rzX1TVFwZemSQNgOOapHEyp99Rq6rrgOsGXIskDY3jmqRx4K9wS5IkdZRBTZIkqaMMapIkSR1lUJMkSeoog5okSVJHGdQkSZI6yqAmSZLUUQY1SZKkjjKoSZIkdZRBTZIkqaMMapIkSR1lUJMkSeoog5okSVJHGdQkSZI6amBBLcm6JNuS3NrXdkiSa5Lc1d4Pbu1J8oEkG5PckuSovnVWt/53JVk9qHolaS5mGNvOT7Ilyc3tdVLfsnPb2HZnkuNHU7WkcTXII2qXAifs0nYOcG1VrQSubfMAJwIr22sNcDH0gh1wHnAMcDRw3lS4k6QRuZQfHtsALqqqVe11NUCSI4HTgBe1df4oyT5Dq1TS2BtYUKuqLwEP7NJ8MnBZm74MOKWv/fLquR5YkuQw4Hjgmqp6oKoeBK5h+gFSkoZihrFtJicDV1TV41X1LWAjvZ1OSZqTYV+jtrSqtrbpe4Glbfpw4J6+fptb20ztktQ1Z7ZLN9b1Hfmf8xiWZE2SDUk2bN++fdC1ShoTI7uZoKoKqIXanoOcpBG6GHg+sArYCrxnvhuoqrVVNVlVkxMTEwtcnqRxNeygdl87pUl739batwDL+/ota20ztf8QBzlJo1JV91XVzqp6AvgQT57enPMYJknTGXZQWw9M3bm5Griqr/0N7e7PY4GH2ynSzwKvTnJwO5Xw6tYmSZ0xtQPavAaYuiN0PXBakgOSHEHvhqmvDrs+SeNr30FtOMlHgZcDhybZTO/uzQuBK5OcDtwNnNq6Xw2cRO9C28eANwFU1QNJfg+4sfX73aqa60W8krTgZhjbXp5kFb3LOTYBbwaoqtuSXAncDuwAzqiqnSMoW9KYGlhQq6rXzbDouGn6FnDGDNtZB6xbwNIkaY/NMLZdMkv/C4ALBleRpMXMJxNIkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJkqSOMqhJkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJkqSOMqhJkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJkqSOMqhJ0jwkWZdkW5Jb+9oOSXJNkrva+8GtPUk+kGRjkluSHDW6yiWNI4OaJM3PpcAJu7SdA1xbVSuBa9s8wInAyvZaA1w8pBolLRIGNUmah6r6EvDALs0nA5e16cuAU/raL6+e64ElSQ4bSqGSFgWDmiQ9dUuramubvhdY2qYPB+7p67e5tUnSnBjUJGkBVVUBNd/1kqxJsiHJhu3btw+gMknjyKAmSU/dfVOnNNv7tta+BVje129Za/shVbW2qiaranJiYmKgxUoaHwY1SXrq1gOr2/Rq4Kq+9je0uz+PBR7uO0UqSbu176gLkKRxkuSjwMuBQ5NsBs4DLgSuTHI6cDdwaut+NXASsBF4DHjT0AuWNNYMapI0D1X1uhkWHTdN3wLOGGxFkhYzT31KkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJkqSOMqhJkiR11EiCWpJNSb6e5OYkG1rbIUmuSXJXez+4tSfJB5JsTHJLkqNGUbMkSdKwjfKI2iuqalVVTbb5c4Brq2olcG2bBzgRWNlea4CLh16pJEnSCHTp1OfJwGVt+jLglL72y6vnemBJksNGUJ8kSdJQjSqoFfC5JDclWdPallbV1jZ9L7C0TR8O3NO37ubW9gOSrEmyIcmG7du3D6puSZKkodl3RJ/7C1W1JclzgGuSfKN/YVVVkprPBqtqLbAWYHJycl7rSpIkddFIjqhV1Zb2vg34FHA0cN/UKc32vq113wIs71t9WWuTJEla1IYe1JL8aJKDpqaBVwO3AuuB1a3bauCqNr0eeEO7+/NY4OG+U6SSJEmL1ihOfS4FPpVk6vP/rKo+k+RG4MokpwN3A6e2/lcDJwEbgceANw2/ZEmSpOEbelCrqm8CPzdN+/3AcdO0F3DGEEqTJEnqlC79PIckSZL6GNQkSZI6yqAmSZLUUQY1SZKkjjKoSZIkdZRBTZIkqaMMapIkSR01qmd9StKik2QT8AiwE9hRVZNJDgE+BqwANgGnVtWDo6pR0njxiJokLaxXVNWqqpps8+cA11bVSuDaNi9Jc2JQk6TBOhm4rE1fBpwyulIkjRuDmiQtnAI+l+SmJGta29Kq2tqm76X3vGNJmhOvUZOkhfMLVbUlyXOAa5J8o39hVVWSmm7FFuzWADzvec8bfKWSxoJH1CRpgVTVlva+DfgUcDRwX5LDANr7thnWXVtVk1U1OTExMaySJXWcQU2SFkCSH01y0NQ08GrgVmA9sLp1Ww1cNZoKJY0jT31K0sJYCnwqCfTG1j+rqs8kuRG4MsnpwN3AqSOsUYvMinP+YtQlaAabLvylBdmOQU2SFkBVfRP4uWna7weOG35FkhYDT31KkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJkqSOMqhJkiR1lEFNkiSpo3yElPZ6PiuvuxbqWXmSNK48oiZJktRRBjVJkqSOMqhJkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkcZ1CRJkjrKoCZJktRRBjVJkqSOMqhJkiR1lEFNkiSpowxqkiRJHWVQkyRJ6qixCWpJTkhyZ5KNSc4ZdT2SNFeOX5L21FgEtST7AB8ETgSOBF6X5MjRViVJu+f4JempGIugBhwNbKyqb1bVPwJXACePuCZJmgvHL0l7bFyC2uHAPX3zm1ubJHWd45ekPbbvqAtYKEnWAGva7KNJ7hxlPSN0KPDtURexEPKuUVcwlhbNvz/M+2/gxwdUxlA4hn3fovkbdgzbI3vrv/+M49e4BLUtwPK++WWt7fuqai2wdphFdVGSDVU1Oeo6NBr++3fSbscvcAyb4t/w3s1//x82Lqc+bwRWJjkiyf7AacD6EdckSXPh+CVpj43FEbWq2pHkTOCzwD7Auqq6bcRlSdJuOX5JeirGIqgBVNXVwNWjrmMM7PWnTvZy/vt3kOPXvPg3vHfz338XqapR1yBJkqRpjMs1apIkSXsdg9oi4mNq9l5J1iXZluTWUdci7QnHr72bY9jMDGqLhI+p2etdCpww6iKkPeH4JRzDZmRQWzx8TM1erKq+BDww6jqkPeT4tZdzDJuZQW3x8DE1ksaV45c0A4OaJElSRxnUFo85PaZGkjrI8UuagUFt8fAxNZLGleOXNAOD2iJRVTuAqcfU3AFc6WNq9h5JPgp8BXhhks1JTh91TdJcOX7JMWxmPplAkiSpozyiJkmS1FEGNUmSpI4yqEmSJHWUQU2SJKmjDGqSJEkdZVDTQCR5dNQ17CrJpiSHDmjbb0zyh4PYtqThcvxSlxjUNNbS49+xpLHj+KW58A9EQ5Pki0km2/ShSTa16f+UZF2b/tkktyb5kSTnJ/nPfevfmmRFe92Z5HLgVuC/JnlfX7/fSHLRHGuaSPKJJDe218uSPK3tvS7p63dXkqXT9V+A/zSSOs7xS6NiUFMXvB94QZLXAB8G3lxVj+1mnZXAH1XVi4D3AL+SZL+27E3Aunl89kVV9RLg3wB/UlVPAFcBrwFIcgxwd1XdN13/uX5JSYuS45cGat9RFyBV1RNJ3gjcAvyvqvrrOax2d1Vd39Z/NMkXgF9OcgewX1V9fY4f/4vAkUmm5p+Z5EDgY8B/ozfwntbmZ+svaS/k+KVBM6hpmHbw5FHcp++ybCXwKPDcGfrvus4/7LL+nwDvBL5Bb3Caq6cBx1bV9/obk3yF3l7yBHAK8Pu76T+Pj5Q0hhy/NBKe+tQwbQL+WZt+7VRjkmcBHwD+BfDsJK/t639U63MUcMRMG66qG4DlwL8DPjqPmj4H/FZfLava9gr4FPBe4I6qun+2/pIWvU04fmkEDGoalB9JsrnvdTbwbuA/JPkboP8284uAD1bV3wGnAxcmeQ7wCeCQJLcBZwJ/t5vPvBL466p6cJY+t/TV9F7gPwKTSW5Jcjvwlr6+HwP+PU+eNmA3/SUtDo5f6oz0grc0/pJ8mt6FsteOuhZJmg/HL83EI2oae0mWJPk74LsOcpLGieOXdscjapIkSR3lETVJkqSOMqhJkiR1lEFNkiSpowxqkiRJHWVQkyRJ6iiDmiRJUkf9f4C914SFZ4SfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].bar(y_train.groupby(y_train).groups.keys(), height=y_train.groupby(y_train).count())\n",
    "axes[0].set_xlabel('Luxury Level')\n",
    "axes[0].set_xticks(list(y_train.groupby(y_train).groups.keys()))\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Train set')\n",
    "axes[1].bar(y_test.groupby(y_test).groups.keys(), height=y_test.groupby(y_test).count())\n",
    "axes[1].set_xlabel('Luxury Level')\n",
    "axes[1].set_xticks(list(y_test.groupby(y_test).groups.keys()))\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['positive', 'negative'], [train_raw['luxury'].sum(), train_raw.shape[0]-train_raw['luxury'].sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is the definition of base rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDuc7YEGfpdx"
   },
   "source": [
    "### Base rate, refers to the probabilities unconditioned on featural evidence. In Bayes' theorem, it is also referred to as Prior probability. \n",
    "\n",
    "### Always calculate base rate with the training dataset, as you should not have information on the labeling of test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is the base rate in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06673920928545521"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['luxury'].sum()/train_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.933261\n",
       "1    0.066739\n",
       "Name: luxury, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using value_counts\n",
    "train_raw['luxury'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simplest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 All Negative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Build a model which always predicts 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# class benchmark_model(BaseEstimator, ClassifierMixin):\n",
    "#     '''\n",
    "#     a model which always predicts 0\n",
    "#     '''\n",
    "#     def __init__(self):\n",
    "#         self.prediction = 0\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, X, y=None):\n",
    "#         return [self.prediction]*len(X)\n",
    "        \n",
    "# # Ref: https://danielhnyk.cz/creating-your-own-estimator-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=0, strategy='constant')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummyc = DummyClassifier(strategy = 'constant', constant = 0)\n",
    "dummyc.fit(train_raw.price, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Make predictions for both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dummyc.predict(train_raw.price)\n",
    "y_test_pred = dummyc.predict(test_raw.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **accuracy_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the training set: 0.933\n",
      "Accuracy score for the testing set: 0.893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy score for the training set: {0:.3f}\".\n",
    "      format(accuracy_score(y_train,y_train_pred)))\n",
    "print(\"Accuracy score for the testing set: {0:.3f}\".\n",
    "      format(accuracy_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How is accuracy score calculated?"
   ]
  },
  {
   "attachments": {
    "832def4a-3efb-4a42-b4ab-cf209c73ed09.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** It is the number of correct predictions made divided by the total number of predictions made.\n",
    "\n",
    "![image.png](attachment:832def4a-3efb-4a42-b4ab-cf209c73ed09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Are the accuracy scores good? Why is that? Is the model useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--KaVRuDfpd1"
   },
   "source": [
    "### Although the score seems high, it is not useful. If we think about how many true 0s we have, we will realize that setting everything to zero will give you a quite 'nice' prediction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How is accuracy score related to base rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the case above, accuracy = 1 - base rate. (They are often not related)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **precision_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709757034851374"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666303953572724"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, y_train_pred, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How is **precision_score** calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6bMDKNCfpd3"
   },
   "source": [
    "### The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative. The best value is 1 and the worst value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> If the **precision_score** for a model is 80%, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX6Hy5Fyfpd3"
   },
   "source": [
    "### 80% of positive predictions are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **recall_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332607907145448"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How is **recall_score** calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whvOBN6mfpd5"
   },
   "source": [
    "### The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> If the **recall_score** for a model is 80%, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esEer-yNfpd5"
   },
   "source": [
    "### 80% of positive cases have been correctly identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **f1_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010431574140803"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48273921200750475"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_pred, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How is **f1_score** calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gckKu_Pyfpd6"
   },
   "source": [
    "### The F1 score can be interpreted as a weighted average of the precision and recall. F1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Why do we need **f1_score**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The F1 score conveys the balance between the precision and the recall. It is a better metric when there are imbalanced classes. In most real-life classification problems, imbalanced class distribution exists and thus F1-score is a better metric to evaluate our model on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Use **classification_report** to get systematic idea about model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      2573\n",
      "           1       0.00      0.00      0.00       184\n",
      "\n",
      "    accuracy                           0.93      2757\n",
      "   macro avg       0.47      0.50      0.48      2757\n",
      "weighted avg       0.87      0.93      0.90      2757\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       383\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.89       429\n",
      "   macro avg       0.45      0.50      0.47       429\n",
      "weighted avg       0.80      0.89      0.84       429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# in binary classification, recall of the positive class is also known as “sensitivity”;\n",
    "# recall of the negative class is “specificity”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       184\n",
      "           0       0.93      1.00      0.97      2573\n",
      "\n",
      "    accuracy                           0.93      2757\n",
      "   macro avg       0.47      0.50      0.48      2757\n",
      "weighted avg       0.87      0.93      0.90      2757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred, labels=[1,0])) # you can specify labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Get the **confusion_matrix** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2573    0]\n",
      " [ 184    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_train, y_train_pred, normalize=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89277389, 0.        ],\n",
       "       [0.10722611, 0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pred:0  pred:1\n",
      "true:0    2573       0\n",
      "true:1     184       0\n"
     ]
    }
   ],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_train, y_train_pred, labels=[0, 1]), \n",
    "    index=['true:0', 'true:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What does every element in the confusion matrix represent, respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFqnSpl8fpd8"
   },
   "source": [
    "### Top left element is true negative, top right is false positive, left bottom is false negative and right bottom is true positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> How can you calculate recall and precision with a confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EPgqwIGfpd9"
   },
   "source": [
    "### You can find the tp, fp and fn from the confusion matrix.\n",
    "\n",
    "Recall: tp / (tp + fn)\n",
    "Precision: tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 All Positive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Build a model which always predicts 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class benchmark_model1(BaseEstimator, ClassifierMixin):\n",
    "#     '''\n",
    "#     a model which always predicts 1\n",
    "#     '''\n",
    "#     def __init__(self):\n",
    "#         self.prediction = 1\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, X, y=None):\n",
    "#         return [self.prediction]*len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyc = DummyClassifier(strategy = 'constant', constant = 1)\n",
    "dummyc.fit(train_raw.price, y_train)\n",
    "y_train_pred_array = dummyc.predict(train_raw.price)\n",
    "y_test_pred_array = dummyc.predict(test_raw.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Make predictions for both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dummyc.predict(train_raw.price)\n",
    "y_test_pred = dummyc.predict(test_raw.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Scores and confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the scores and confusion matrices of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the training set: 0.067\n",
      "Accuracy score for the testing set: 0.107\n",
      "Precision score for the training set: 0.033\n",
      "Precision score for the testing set: 0.054\n",
      "Recall score for the training set: 0.500\n",
      "Recall score for the testing set: 0.500\n",
      "F1 score for the training set: 0.063\n",
      "F1 score for the testing set: 0.097\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for the training set: {0:.3f}\".\n",
    "      format(accuracy_score(y_train,y_train_pred)))\n",
    "print(\"Accuracy score for the testing set: {0:.3f}\".\n",
    "      format(accuracy_score(y_test,y_test_pred)))\n",
    "\n",
    "print(\"Precision score for the training set: {0:.3f}\".\n",
    "      format(precision_score(y_train,y_train_pred, average='macro')))\n",
    "print(\"Precision score for the testing set: {0:.3f}\".\n",
    "      format(precision_score(y_test,y_test_pred, average='macro')))\n",
    "\n",
    "print(\"Recall score for the training set: {0:.3f}\".\n",
    "      format(recall_score(y_train,y_train_pred, average='macro')))\n",
    "print(\"Recall score for the testing set: {0:.3f}\".\n",
    "      format(recall_score(y_test,y_test_pred, average='macro')))\n",
    "\n",
    "print(\"F1 score for the training set: {0:.3f}\".\n",
    "      format(f1_score(y_train,y_train_pred, average='macro')))\n",
    "print(\"F1 score for the testing set: {0:.3f}\".\n",
    "      format(f1_score(y_test,y_test_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2573\n",
      "           1       0.07      1.00      0.13       184\n",
      "\n",
      "    accuracy                           0.07      2757\n",
      "   macro avg       0.03      0.50      0.06      2757\n",
      "weighted avg       0.00      0.07      0.01      2757\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       383\n",
      "           1       0.11      1.00      0.19        46\n",
      "\n",
      "    accuracy                           0.11       429\n",
      "   macro avg       0.05      0.50      0.10       429\n",
      "weighted avg       0.01      0.11      0.02       429\n",
      "\n",
      "[[   0 2573]\n",
      " [   0  184]]\n",
      "[[  0 383]\n",
      " [  0  46]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the difference between all-positive and all-negative models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just focus on the positive label:\n",
    "- Accuracy score of the all-positive model is the same as the base rate and equal to 1 - accuracy score of the all-negative model.\n",
    "- Precision of the all-negative model is 0 because there are no positive predictions; precision of the all-positive model is low because there are many false positives.\n",
    "- Recall of the all-negative model is 0 because there are no positive predictions; recall of the all-positive model is 1 because there are no  negative predictions (thus no false negative).\n",
    "- F1 score of the all-negative model is 0 because recall and precision are 0; F1 score of the all-positive model is low despite recall being 1 because precision is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Classification metrics\n",
    "- Precision: TP/(TP+FP); Among predicted positives, how many are true?\n",
    "- Recall: TP/(TP+FN); Among all positives, how many are predicted?\n",
    "- Accuracy: (TP+TN)/(TP+FP+TN+FN); Measure of all the correctly classified observations. Good for balanced classes.\n",
    "- F-1 Score: 2/(1/Precision + 1/Recall); Harmonic mean of precision and recall. Good for imbalanced classes.\n",
    "- ROC_AUC: measure model’s capability to distinguish positive and negative class and is insensitive to class balance. \n",
    "- Sensitivity: the ability of a test to correctly identify patients with a disease. TP/(TP+FN) = Recall = True Positive Rate\n",
    "- Specificity: the ability of a test to correctly identify people without the disease. TN/(TN+FP) = 1 - False Positive Rate\n",
    "\n",
    "2. Understand when to use what metrics (find some examples yourself):\n",
    "- Precision is particularly useful when the costs of False Positives is high.\n",
    "- Recall is particularly useful when the cost of False Negatives is high.\n",
    "\n",
    "3. Average methods for recall and precision\n",
    "- Binary: default value, only report results for the class specified by pos_label. Binary is applicable only if targets are binary.\n",
    "- Micro: now replaced by accuracy.\n",
    "- Macro: unweighted mean for all classes. e.g., macro recall = 0.5*(recall_pos + recall_neg)\n",
    "- Weighted: weighted mean for all classes. e.g., weighted recall = recall_ pos * weight_pos + recall_ neg * weight_neg, where weight_pos = count_pos/count_all, weight_neg = count_neg/count_all\n",
    "\n",
    "4. How to assess if a dataset is imbalanced? Look at the base rates (event rates). No hard cutoff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
