{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tFM4YKSJ1Yv"
   },
   "source": [
    "## From this notebook, we are going to build classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FyM-cqFuJ1Yx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E8KKe5lqJ1Yy"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/sales.csv')\n",
    "df = pd.read_csv('sales.csv')\n",
    "df.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vCIvbK6OJ1Yy"
   },
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df.purchase_date).dt.year\n",
    "train_raw = df[df.year < 2015].copy() # copy here to get rid of the copy warning\n",
    "test_raw = df[df.year >= 2015].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFsN5FdWJ1Yz"
   },
   "source": [
    "# 1. Generate Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNhvxZdNJ1Yz"
   },
   "source": [
    "<font color='red'>Assignment:</font> We define a categorical target **luxury**. If **price** is higher than 500k dollars, we say this item is a **luxury**, and use integer 1 to mark it as positive. Otherwise, we use 0 to mark it as negative. Get the target Series for training and testing data sets (**y_train** and **y_test**), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc0s8MpZJ1Yz"
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEHssT4VJ1Y0"
   },
   "outputs": [],
   "source": [
    "# train_raw['price'] = train_raw['price'].map(lambda x: x if type(x) is float else float(x.strip('$').replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TV1A8EGvJ1Y0"
   },
   "outputs": [],
   "source": [
    "# test_raw['price'] = test_raw['price'].map(lambda x: x if type(x) is float else float(x.strip('$').replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quw3nG-HJ1Y1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_raw['luxury'] = ''\n",
    "# test_raw['luxury'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SmuUEtQJ1Y1"
   },
   "outputs": [],
   "source": [
    "# train_raw['luxury'].values[:] = 0\n",
    "# test_raw['luxury'].values[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz8OA_fZJ1Y1"
   },
   "outputs": [],
   "source": [
    "# train_raw['luxury'][train_raw[train_raw.price > 500000].index] = 1\n",
    "# test_raw['luxury'][test_raw[test_raw.price > 500000].index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d4YViqJ2J1Y2"
   },
   "outputs": [],
   "source": [
    "train_raw[\"luxury\"] = train_raw[\"price\"].map(lambda x: 1 if float(x.strip(\"$\").replace(\",\", \"\")) > 500000 else 0)\n",
    "test_raw[\"luxury\"] = test_raw[\"price\"].map(lambda x: 1 if float(x.strip(\"$\").replace(\",\", \"\")) > 500000 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kBH75ysZJ1Y2"
   },
   "outputs": [],
   "source": [
    "y_train = train_raw.luxury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "usiizErbJ1Y2"
   },
   "outputs": [],
   "source": [
    "y_test = test_raw.luxury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqDAYEtgJ1Y3"
   },
   "source": [
    "<font color='red'>Assignment:</font> Visualize the comparison between the numbers of positive and negative data points. **Hint:** You could use either bar chart or pie chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osZ2JS1rNGHv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "udAcVM-uJ1Y3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7356XNUNJ1Y3",
    "outputId": "df6bce8f-b182-41b5-d37e-b3ae952495e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['positive', 'negative'], [train_raw['luxury'].sum(), train_raw.shape[0]-train_raw['luxury'].sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e736K4AJ1Y4"
   },
   "source": [
    "#### <font color='red'>Note:</font> you can use any modules/functions to plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-P07dhUJ1Y4"
   },
   "source": [
    "<font color='red'>Question:</font> What is the definition of base rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz-JruX1J1Y4"
   },
   "source": [
    "### Base rate, refers to the probabilities unconditioned on featural evidence. In Bayes' theorem, it is also referred to as Prior probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYUaET29J1Y4"
   },
   "source": [
    "<font color='red'>Question:</font> What is the base rate in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UCaEbLWUJ1Y4",
    "outputId": "23c6ef36-5bbb-41ad-9543-90312a62d52c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06673920928545521"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['luxury'].sum()/train_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RWNXD8rIJ1Y5",
    "outputId": "d23edbfa-723a-422f-af56-3bbd2d7be04d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.933261\n",
       "1    0.066739\n",
       "Name: luxury, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using value_counts\n",
    "train_raw['luxury'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJ-k2IRMJ1Y5"
   },
   "source": [
    "#### <font color='red'>Note:</font> always check for train. How about test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka_EnsmrJ1Y5"
   },
   "source": [
    "# 2. Simplest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMnpnBEQJ1Y5"
   },
   "source": [
    "## 2.1 All Negative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3uTpegPJ1Y5"
   },
   "source": [
    "### 2.1.1 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd6TlpvpJ1Y5"
   },
   "source": [
    "<font color='red'>Assignment:</font> Build a model which always predicts 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2msrS5cCJ1Y5"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s-tIexGtJ1Y6"
   },
   "outputs": [],
   "source": [
    "dummyc = DummyClassifier(strategy = 'constant', constant = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JZQxp6_dJ1Y6",
    "outputId": "824aeaf4-ba8f-4590-f386-50982793702c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=0, strategy='constant')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyc.fit(train_raw.price, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtlWncv3J1Y6"
   },
   "source": [
    "#### <font color='red'>Note:</font> build your own class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbbtGzMaJ1Y6"
   },
   "source": [
    "<font color='red'>Assignment:</font> Make predictions for both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HS9arqPOJ1Y6"
   },
   "outputs": [],
   "source": [
    "y_train_pred = dummyc.predict(train_raw.price)\n",
    "y_test_pred = dummyc.predict(test_raw.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4yXOWmr8J1Y6",
    "outputId": "20897bb2-d113-4da9-f531-04bdc777b8ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aGZ44HrAJ1Y6",
    "outputId": "28614f0a-c1c0-4348-f8da-dbda17813cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_dIq3qaJ1Y6"
   },
   "source": [
    "### 2.1.2 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP0mTbprJ1Y7"
   },
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **accuracy_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MgaeLhbxJ1Y7",
    "outputId": "bdce7bb0-8a03-41bc-8dfa-a03c4e53c112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332607907145448"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2Qnx3tKQJ1Y7",
    "outputId": "71396eef-d55e-474d-aac7-b67efb6a5742"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8927738927738927"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbG9AKSWJ1Y7"
   },
   "source": [
    "<font color='red'>Question:</font> How is accuracy score calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOkiWZkYJ1Y7"
   },
   "source": [
    "### The score computes subset accuracy. It gives the same result as the score function in the DummyClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4tyG6EmJ1Y7"
   },
   "source": [
    "<font color='red'>Question:</font> Are the accuracy scores good? Why is that? Is the model useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkzfQVQAJ1Y7"
   },
   "source": [
    "### Although the score seems high, it is not useful. If we think about how many true 0s we have, we will realize that setting everything to zero will give you a quite 'nice' prediction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcjB27zRJ1Y7"
   },
   "source": [
    "<font color='red'>Question:</font> How is accuracy score related to base rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KO-ccFB0J1Y8"
   },
   "source": [
    "### <font color = 'blue'> It is 1 - base rate </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7xVBeyIJ1Y8"
   },
   "source": [
    "### 2.1.2 Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgEKQ5MYJ1Y8"
   },
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **precision_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KNwNncEAJ1Y8",
    "outputId": "2403c974-3f38-4831-a326-db80033ded1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4666303953572724"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GsCd-m8VJ1Y8",
    "outputId": "9d493321-4f16-4c88-9200-33f970e98e61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44638694638694637"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCpCdOCfJ1Y8"
   },
   "source": [
    "<font color='red'>Question:</font> How is **precision_score** calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKYZvOHwJ1Y8"
   },
   "source": [
    "### The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative. The best value is 1 and the worst value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvt8c1qdJ1Y9"
   },
   "source": [
    "<font color='red'>Question:</font> If the **precision_score** for a model is 80%, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LMyFVklJ1Y9"
   },
   "source": [
    "### It means for all my positive predictions, there are 80% actually positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18A0ebX_J1Y9"
   },
   "source": [
    "### 2.1.3 Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0aPn-yeJ1Y9"
   },
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **recall_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jta1jbhGJ1Y9",
    "outputId": "cb034dbc-031d-4da7-ebf3-7a92b7017386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sOMLgE2DJ1Y9",
    "outputId": "850c471c-437b-42f5-894e-484db69881aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZA9PwSOhJ1Y-"
   },
   "source": [
    "<font color='red'>Question:</font> How is **recall_score** calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-zHrlWMJ1Y-"
   },
   "source": [
    "### The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6r5App1J1Y-"
   },
   "source": [
    "<font color='red'>Question:</font> If the **recall_score** for a model is 80%, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmG6Kn8hJ1Y-"
   },
   "source": [
    "### Over all the real positives, I correctly identified 80% of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TH-ympfYJ1Y-"
   },
   "source": [
    "### 2.1.4 F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn0ExzyuJ1Y-"
   },
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing **f1_score**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wxGyO130J1Y-",
    "outputId": "0890714a-ec4e-4c4b-f9dc-75d4e3f2228a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48273921200750475"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lhqEkcDpJ1Y-",
    "outputId": "9be4ab76-2a38-4181-abb8-dcf6359bcb5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47167487684729065"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJWkVVnjJ1Y-"
   },
   "source": [
    "<font color='red'>Question:</font> How is **f1_score** calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4q1Pi5WJ1Y_"
   },
   "source": [
    "### The F1 score can be interpreted as a weighted average of the precision and recall. F1 = 2 * (precision * recall) / (precision + recall)\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWq_WSvtJ1Y_"
   },
   "source": [
    "<font color='red'>Question:</font> Why do we need **f1_score**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MszFP7STJ1Y_"
   },
   "source": [
    "### F1 Score is needed when you want to seek a balance between Precision and Recall if there is an uneven distribution (large number of Actual Negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLtsjG48J1Y_"
   },
   "source": [
    "### 2.1.5 Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IdOoWytJ1Y_"
   },
   "source": [
    "<font color='red'>Assignment:</font> Use **classification_report** to get systematic idea about model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "N_IM3ZUGJ1Y_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4_WEYwfjJ1Y_",
    "outputId": "81a86695-6e21-42b3-bb3f-8502fff22484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332607907145448"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tJLJR3apJ1Y_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      2573\n",
      "           1       0.00      0.00      0.00       184\n",
      "\n",
      "    accuracy                           0.93      2757\n",
      "   macro avg       0.47      0.50      0.48      2757\n",
      "weighted avg       0.87      0.93      0.90      2757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\zhuy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\zhuy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_train, y_train_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "i5DfEqMgJ1Y_"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMHERRo2J1Y_"
   },
   "source": [
    "### <font color = 'blue'> Can we discuss the relation between model performance and these scores? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMp6PiC8J1ZA"
   },
   "source": [
    "### 2.1.6 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYuBed2wJ1ZA"
   },
   "source": [
    "<font color='red'>Assignment:</font> Get the **confusion_matrix** of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGiIQ89kJ1ZA"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHkAu94AJ1ZA",
    "outputId": "13e96ed0-b7ab-4ee0-9df7-9ccfebacc7dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2573,    0],\n",
       "       [ 184,    0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yscggv7oJ1ZA",
    "outputId": "b91b1349-7ac2-492f-d759-5ae3de8cf6d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[383,   0],\n",
       "       [ 46,   0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7fNnKK6J1ZA"
   },
   "source": [
    "<font color='red'>Question:</font> What does every element in the confusion matrix represent, respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_ey2ngSJ1ZA"
   },
   "source": [
    "### Top left element is true negative, top right is false positive, left bottom is false negative and right bottom is true positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e84SglY0J1ZA"
   },
   "source": [
    "<font color='red'>Question:</font> How can you calculate recall and precision with a confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBCvfnmkJ1ZA"
   },
   "source": [
    "### You can find the tp, fp and fn from the confusion matrix.\n",
    "<br>Recall: tp / (tp + fn)\n",
    "<br>Precision: tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APZbVEPDJ1ZA"
   },
   "source": [
    "## 2.2 All Positive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG_OZKCqJ1ZA"
   },
   "source": [
    "### 2.2.1 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zMEXBsCJ1ZB"
   },
   "source": [
    "<font color='red'>Assignment:</font> Build a model which always predicts 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWdiMxedJ1ZB",
    "outputId": "e48ef4fe-bf39-4e47-a981-495b89408bd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=1, strategy='constant')"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyc = DummyClassifier(strategy = 'constant', constant = 1)\n",
    "dummyc.fit(train_raw.price, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_AppwO4J1ZB"
   },
   "source": [
    "<font color='red'>Assignment:</font> Make predictions for both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wt6h-E3cJ1ZB"
   },
   "outputs": [],
   "source": [
    "y_train_pred = dummyc.predict(train_raw.price)\n",
    "y_test_pred = dummyc.predict(test_raw.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9z7hps5J1ZB"
   },
   "source": [
    "### 2.2.2 Scores and confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KQQM0YMJ1ZB"
   },
   "source": [
    "<font color='red'>Assignment:</font> Calculate the scores and confusion matrices of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQTGvygeJ1ZB",
    "outputId": "e5f5bab3-3bfc-4c7d-f90e-547617f0e969"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06673920928545521"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMReUKGiJ1ZB",
    "outputId": "12c997fc-8eec-4893-df61-a54abd189dda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10722610722610723"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTUs4D7zJ1ZB",
    "outputId": "e4d2ffae-c223-4e7c-82d2-b67722d984c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033369604642727604"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-Ozh-kTJ1ZB",
    "outputId": "299df127-f090-4f9c-d69d-12826de43c50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053613053613053616"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6hMyIXqJ1ZC",
    "outputId": "50341cce-eecc-4810-96f1-d147f34bd93f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyuFgYHlJ1ZC",
    "outputId": "7a2239c3-7987-4418-c96f-9d8c65ff45cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlPg5TrbJ1ZC",
    "outputId": "74fc3230-c450-4286-b891-f4ec5e06879b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06256375382522951"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9VO9mwYJ1ZC",
    "outputId": "f06d272d-88ac-42af-8e40-30e4aa5704fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09684210526315791"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2J0JIs9J1ZC",
    "outputId": "04ccb6f1-fff3-4750-a63a-6dda8e164ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2573],\n",
       "       [   0,  184]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQ78tK_-J1ZC",
    "outputId": "63dd08f9-a35b-4645-e0ad-954f9377d6b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 383],\n",
       "       [  0,  46]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lH1QWfkuJ1ZC",
    "outputId": "4c5cd261-6958-428a-f001-1bf075b0ad78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06673920928545521"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred, pos_label=1, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3sx2tRRJ1ZC",
    "outputId": "c8b12e08-a0ac-47a5-81f5-f29996541c7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2573\n",
      "           1       0.07      1.00      0.13       184\n",
      "\n",
      "    accuracy                           0.07      2757\n",
      "   macro avg       0.03      0.50      0.06      2757\n",
      "weighted avg       0.00      0.07      0.01      2757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKbk5uzXJ1ZD",
    "outputId": "f5ba4fed-2ad1-455d-c4c4-1b996b64df70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       383\n",
      "           1       0.11      1.00      0.19        46\n",
      "\n",
      "    accuracy                           0.11       429\n",
      "   macro avg       0.05      0.50      0.10       429\n",
      "weighted avg       0.01      0.11      0.02       429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atjs7IszJ1ZD"
   },
   "source": [
    "<font color='red'>Question:</font> What are the difference between all-positive and all-negative models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7HqHQ6OJ1ZD"
   },
   "source": [
    "### Because most of the data in this model are 0s, for the all-negative model, accuracy, precision and f1 are all high while they are all low for all-positive model. However, the recall stays the same for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lB5IOUWLJ1ZD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "17_simplest_classification_models_updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
